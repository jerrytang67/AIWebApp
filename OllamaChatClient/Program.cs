using System.Net.Http.Json;
using Codeblaze.SemanticKernel.Connectors.Ollama.ChatCompletion;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using Newtonsoft.Json;

Console.OutputEncoding = System.Text.Encoding.UTF8;
using HttpClient client = new();
client.BaseAddress = new Uri("http://localhost:11434");

while (true) {
    Console.Write("请输入问题：");
    var q = Console.ReadLine();
    var data = new {
        model = "llama3:8b",
        messages = new[] {
            new {
                role = "system",
                content = "你是一个全知全能的中文助手,你叫哒哒,请把问题用简短的中文回答"
            },
            new {
                role = "user",
                content = q
            }
        },
        stream = true
    };
    var response = await client.PostAsJsonAsync("/api/chat", data).ConfigureAwait(false);
    var stream = await response.Content.ReadAsStreamAsync().ConfigureAwait(false);
    using var reader = new StreamReader(stream);
    var jsonReader = new JsonTextReader(reader) {
        SupportMultipleContent = true // Important to support jsonl format
    };
    var jsonSerializer = new JsonSerializer();
    var done = false;

    while (!done && jsonReader.Read()) {
        var message = jsonSerializer.Deserialize<OllamaChatResponseMessage>(jsonReader);
        if (message != null) {
            done = message.Done;
            Console.Write(message?.Message.Content);
        }
    }

    Console.WriteLine();
    Console.WriteLine();
}

namespace Codeblaze.SemanticKernel.Connectors.Ollama.ChatCompletion {
    public class OllamaChatResponseMessageContent {
        /// <summary>
        /// The role of the author of the message either "system", "user", or "assistant".
        /// </summary>
        [JsonProperty("role")]
        public string Role { get; set; } = null!;

        /// <summary>
        /// The message content
        /// </summary>
        [JsonProperty("content")]
        public string Content { get; set; } = null!;
    }

    public class OllamaChatResponseMessage : OllamaResponseMessage {
        // 这是一个默认构造函数
        public OllamaChatResponseMessage() {
        }

        // 这是一个带有参数的构造函数，并且被JsonConstructor属性标记
        [JsonConstructor]
        public OllamaChatResponseMessage(string role, string content) {
            Message = new OllamaChatResponseMessageContent {
                Role = role,
                Content = content
            };
        }


        /// <summary>
        /// The message generated by the chat model.
        /// </summary>
        public OllamaChatResponseMessageContent Message { get; set; } = null!;

        public ChatMessageContent ToChatMessageContent() {
            var metadata = new Dictionary<string, object>() {
                { "total_duration", TotalDuration },
                { "load_duration", LoadDuration },
                { "prompt_eval_count", PromptEvalCount },
                { "prompt_eval_duration", PromptEvalDuration },
                { "eval_count", EvalCount },
                { "eval_duration", EvalDuration }
            };

            return new ChatMessageContent(
                role: new AuthorRole(Message.Role),
                content: Message.Content,
                modelId: Model,
                metadata: metadata!);
        }

        internal StreamingChatMessageContent ToStreamingChatMessageContent() {
            var metadata = new Dictionary<string, object>() {
                { "total_duration", TotalDuration },
                { "load_duration", LoadDuration },
                { "prompt_eval_count", PromptEvalCount },
                { "prompt_eval_duration", PromptEvalDuration },
                { "eval_count", EvalCount },
                { "eval_duration", EvalDuration }
            };

            return new StreamingChatMessageContent(
                role: new AuthorRole(Message.Role),
                content: Message.Content,
                modelId: Model,
                metadata: metadata!);
        }
    }
}

namespace Codeblaze.SemanticKernel.Connectors.Ollama {
    public class OllamaResponseMessage {
        /// <summary>
        /// The model used to generate the response.
        /// </summary>
        [JsonProperty("model")]
        public string Model { get; set; } = null!;

        /// <summary>
        /// The message created date.
        /// </summary>
        [JsonProperty("created_at")]
        public DateTime CreatedAt { get; set; }

        /// <summary>
        /// Value indicating whether the message is done.
        /// </summary>
        [JsonProperty("done")]
        public bool Done { get; set; } = false!;

        /// <summary>
        /// The time spent generating the response.
        /// </summary>
        [JsonProperty("total_duration")]
        public UInt64 TotalDuration { get; set; } = 0;

        /// <summary>
        /// The time spent in nanoseconds loading the model.
        /// </summary>
        [JsonProperty("load_duration")]
        public UInt64 LoadDuration { get; set; } = 0;

        /// <summary>
        /// The number of tokens in the prompt.
        /// </summary>
        [JsonProperty("generate_duration")]
        public int PromptEvalCount { get; set; } = 0;

        /// <summary>
        /// The time spent in nanoseconds evaluating the prompt.
        /// </summary>
        [JsonProperty("prompt_eval_count")]
        public UInt64 PromptEvalDuration { get; set; } = 0;

        /// <summary>
        /// The number of tokens the response.
        /// </summary>
        [JsonProperty("eval_count")]
        public int EvalCount { get; set; } = 0;

        /// <summary>
        /// The time in nanoseconds spent generating the response.
        /// </summary>
        [JsonProperty("eval_duration")]
        public UInt64 EvalDuration { get; set; }
    }
}